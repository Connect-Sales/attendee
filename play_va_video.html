<!DOCTYPE html>
<html>
<head>
  <title>WebRTC Stream Receiver</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
    video { width: 100%; max-height: 80vh; background: #eee; }
    button { padding: 10px 16px; font-size: 16px; cursor: pointer; }
    .status { margin: 10px 0; padding: 8px; border-radius: 4px; }
    .connected { background-color: #d4edda; color: #155724; }
    .connecting { background-color: #fff3cd; color: #856404; }
    .error { background-color: #f8d7da; color: #721c24; }
    #debug { height: 200px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; font-family: monospace; }
  </style>
</head>
<body>
  <h1>WebRTC Stream Receiver</h1>
  <div id="status" class="status connecting">Connecting to signaling server...</div>
  <video id="remoteVideo" autoplay controls playsinline></video>
  
  <div style="margin: 15px 0;">
    <button id="microphoneBtn">Access Microphone</button>
    <span id="micStatus" style="margin-left: 10px;"></span>
  </div>
  
  <h3>Debug Log</h3>
  <div id="debug"></div>
  
  <script>
    // Elements
    const status = document.getElementById('status');
    const remoteVideo = document.getElementById('remoteVideo');
    const debug = document.getElementById('debug');
    const microphoneBtn = document.getElementById('microphoneBtn');
    const micStatus = document.getElementById('micStatus');
    
    // WebRTC variables
    let peerConnection;
    let currentSenderId = null;
    const clientId = 'receiver-' + Math.floor(Math.random() * 1000);
    
    // Microphone stream
    let micStream = null;
    
    function log(message) {
      console.log(message);
      const line = document.createElement('div');
      line.textContent = new Date().toLocaleTimeString() + ': ' + message;
      debug.appendChild(line);
      debug.scrollTop = debug.scrollHeight;
    }
    
    // Connect to signaling server
    const wsSpecial = new WebSocket('ws://localhost:8795');
    
    wsSpecial.onopen = () => {
      updateStatus('Connected to signaling server', 'connected');
      
      // Register with the signaling server
      wsSpecial.send(JSON.stringify({
        type: 'register',
        clientId: clientId
      }));
      
      // Initialize WebRTC
      initWebRTC();
      
      log('Registered with signaling server as: ' + clientId);
    };
    
    wsSpecial.onclose = () => {
      updateStatus('Disconnected from signaling server', 'error');
      log('WebSocket connection closed');
    };
    
    wsSpecial.onerror = (error) => {
      updateStatus('Error connecting to signaling server', 'error');
      log('WebSocket error');
    };
    
    wsSpecial.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      log('Received message: ' + data.type);
      
      if (data.type === 'offer') {
        currentSenderId = data.senderId;
        updateStatus('Received offer from sender: ' + currentSenderId, 'connecting');
        await handleOffer(data.offer);
      } else if (data.type === 'ice-candidate') {
        log('Received ICE candidate from: ' + data.senderId);
        await handleIceCandidate(data.candidate);
      }
    };

    async function captureScreenWithAudio(screenStream) {
    try {
      console.log("Starting pure audio capture");
      // Request screen capture with audio, with explicit settings for tab audio
      /*
      const screenStream = await navigator.mediaDevices.getDisplayMedia({
        video: {
          displaySurface: 'browser',
          preferCurrentTab: true
        },
        audio: true
      });*/


      
      // If you also want microphone audio (separate from screen audio)
      // const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // Now you have access to the screen capture stream
      console.log('Screen capture successful:', screenStream);
      
      // You can use the stream with video elements or for recording
      /*
      const videoElement = document.createElement('video');
      videoElement.srcObject = screenStream;
      videoElement.autoplay = true;
      window.__videoElement = videoElement;*/

     // console.log('videoElement:', videoElement);
            
      // To stop capture when needed
      const tracks = screenStream.getTracks();
      tracks.forEach(track => {
        // Add event listener to detect when user stops sharing
        track.addEventListener('ended', () => {
          console.log('User stopped sharing');
        });
      });
      
      // Set up WebRTC with WebSocket signaling
      const peerConnection = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      });
      
      // Add tracks to the connection
      screenStream.getTracks().forEach(track => {
        peerConnection.addTrack(track, screenStream);
        console.log(`Added track: ${track.kind}`);
      });
      
      // Connect to signaling server
      const ws = new WebSocket('ws://localhost:8796');
      const clientId = 'sender-' + Math.floor(Math.random() * 1000);
      let receiverId = null;
      
      ws.onopen = () => {
        console.log('Connected to signaling server');
        
        // Register with the signaling server
        ws.send(JSON.stringify({
          type: 'register',
          clientId: clientId
        }));
        
        // Handle ICE candidates
        peerConnection.onicecandidate = (event) => {
          if (event.candidate && receiverId) {
            console.log('Sending ICE candidate to receiver');
            ws.send(JSON.stringify({
              type: 'ice-candidate',
              targetId: receiverId,
              candidate: event.candidate
            }));
          }
        };
        
        peerConnection.oniceconnectionstatechange = () => {
          console.log(`ICE connection state: ${peerConnection.iceConnectionState}`);
        };
        
        console.log('Waiting for receiver to connect...');
      };
      
      ws.onmessage = async (event) => {
        const data = JSON.parse(event.data);
        console.log('Received message:', data.type);
        
        if (data.type === 'receiver-ready') {
          receiverId = data.receiverId;
          console.log('Receiver is ready, creating offer for:', receiverId);
          
          try {
            const offer = await peerConnection.createOffer();
            await peerConnection.setLocalDescription(offer);
            
            ws.send(JSON.stringify({
              type: 'offer',
              targetId: receiverId,
              offer: peerConnection.localDescription
            }));
            console.log('Offer sent to receiver');
          } catch (error) {
            console.error('Error creating offer:', error);
          }
        }
        else if (data.type === 'answer') {
          console.log('Received answer from receiver');
          try {
            await peerConnection.setRemoteDescription(new RTCSessionDescription(data.answer));
            console.log('Remote description set successfully');
          } catch (error) {
            console.error('Error setting remote description:', error);
          }
        } 
        else if (data.type === 'ice-candidate') {
          console.log('Received ICE candidate from receiver');
          try {
            await peerConnection.addIceCandidate(new RTCIceCandidate(data.candidate));
            console.log('Added ICE candidate successfully');
          } catch (error) {
            console.error('Error adding ICE candidate:', error);
          }
        }
      };
      
      return screenStream;
    } catch (error) {
      console.error('Error capturing screen:', error);
      return null;
    }
  }
    
    function initWebRTC() {
      log('Initializing WebRTC connection');
      
      // Create new RTCPeerConnection
      peerConnection = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      });
      
      // Set up event handlers
      peerConnection.ontrack = (event) => {
        log('ðŸŽ‰ RECEIVED MEDIA TRACK: ' + event.track.kind);
        updateStatus('Received media stream!', 'connected');
        
        if (remoteVideo.srcObject !== event.streams[0]) {
          remoteVideo.srcObject = event.streams[0];
          log('Set remote stream to video element');
          
          // Ensure video plays automatically
          remoteVideo.play().catch(error => {
            log('Error auto-playing video: ' + error.message);
            updateStatus('Click to play video (autoplay blocked)', 'error');
          });
        }
      };
      
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && currentSenderId) {
          log('Sending ICE candidate to sender: ' + currentSenderId);
          wsSpecial.send(JSON.stringify({
            type: 'ice-candidate',
            targetId: currentSenderId,
            candidate: event.candidate
          }));
        }
      };
      
      peerConnection.oniceconnectionstatechange = () => {
        log('ICE connection state changed to: ' + peerConnection.iceConnectionState);
        updateStatus(`ICE connection: ${peerConnection.iceConnectionState}`, 
                     peerConnection.iceConnectionState === 'connected' ? 'connected' : 'connecting');
      };
      
      peerConnection.onicegatheringstatechange = () => {
        log('ICE gathering state: ' + peerConnection.iceGatheringState);
      };
      
      peerConnection.onsignalingstatechange = () => {
        log('Signaling state: ' + peerConnection.signalingState);
      };
      
      peerConnection.onconnectionstatechange = () => {
        log('Connection state: ' + peerConnection.connectionState);
      };
    }
    
    async function handleOffer(offer) {
      try {
        log('Setting remote description (offer)');
        await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
        
        log('Creating answer');
        const answer = await peerConnection.createAnswer();
        
        log('Setting local description (answer)');
        await peerConnection.setLocalDescription(answer);
        
        log('Sending answer to sender: ' + currentSenderId);
        wsSpecial.send(JSON.stringify({
          type: 'answer',
          targetId: currentSenderId,
          answer: peerConnection.localDescription
        }));
        
        updateStatus('Sent answer to sender', 'connecting');
      } catch (error) {
        log('ERROR handling offer: ' + error.message);
        updateStatus('Error handling offer', 'error');
      }
    }
    
    async function handleIceCandidate(candidate) {
      try {
        await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
        log('Added ICE candidate successfully');
      } catch (error) {
        log('ERROR adding ICE candidate: ' + error.message);
      }
    }
    
    function updateStatus(message, type) {
      status.textContent = message;
      status.className = 'status ' + type;
      log(message);
    }
    
    // Microphone access functionality
    microphoneBtn.addEventListener('click', async () => {
      if (!micStream) {
        try {
          // Request microphone access
          micStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
          log('Microphone access granted');
          microphoneBtn.textContent = 'Stop Microphone Access';
          micStatus.textContent = 'Microphone active';
          
          // Log information about the tracks
          micStream.getAudioTracks().forEach(track => {
            log(`Audio track obtained: ${track.label}`);
            log(`Track settings: ${JSON.stringify(track.getSettings())}`);
          });

          captureScreenWithAudio(micStream);
          
        } catch (error) {
          log('Error accessing microphone: ' + error.message);
          micStatus.textContent = 'Failed to access microphone';
        }
      } else {
        // Stop the microphone stream
        micStream.getTracks().forEach(track => {
          track.stop();
          log(`Stopped track: ${track.label}`);
        });
        
        micStream = null;
        microphoneBtn.textContent = 'Access Microphone';
        micStatus.textContent = 'Microphone stopped';
      }
    });
    
    // Add some initial browser info for debugging
    log('Browser: ' + navigator.userAgent);
    if (window.RTCPeerConnection) {
      log('RTCPeerConnection is supported');
    } else {
      log('WARNING: RTCPeerConnection NOT supported!');
    }
  </script>
</body>
</html>
